apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-server-v2
  labels:
    {{- include "machina.labels" . | nindent 4 }}
spec:
  {{- if not .Values.autoscaling.enabled }}
  replicas: {{ .Values.replicaCount }}
  {{- end }}
  selector:
    matchLabels:
      {{- include "machina.llmserver.selectorLabels" . | nindent 6 }}
  template:
    metadata:
      {{- with .Values.podAnnotations }}
      annotations:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      labels:
        {{- include "machina.llmserver.selectorLabels" . | nindent 8 }}
        {{- include "machina.podLabels" . | nindent 8 }}
    spec:
      hostNetwork: true
      {{- with .Values.imagePullSecrets }}
      imagePullSecrets:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      serviceAccountName: {{ include "machina.serviceAccountName" . }}
      volumes:
      - name: {{ .Values.components.llmserver.volume.name }}
        persistentVolumeClaim:
          claimName: {{ .Values.components.llmserver.volume.claimName }}
      - name: device-plugin
        hostPath:
          path: /var/lib/kubelet/device-plugins
      - name: libnvidia
        hostPath:
          path: /usr/lib/x86_64-linux-gnu
      initContainers:
      - name: volume-permission
        image: busybox
        command: ["sh", "-c", "chown -R 5001:5001 {{ .Values.components.llmserver.volume.mountPath }}"]
        volumeMounts:
        - name: {{ .Values.components.llmserver.volume.name }}
          mountPath: {{ .Values.components.llmserver.volume.mountPath }}
        securityContext:
          runAsUser: 0
      containers:
      - name: {{ .Chart.Name }}
        volumeMounts:
        - name: {{ .Values.components.llmserver.volume.name }}
          mountPath: {{ .Values.components.llmserver.volume.mountPath }}
        - name: device-plugin
          mountPath: /var/lib/kubelet/device-plugins
        - name: libnvidia
          mountPath: /usr/lib/x86_64-linux-gnu
        image: {{ include "machina.llmserver.image" . }}
        imagePullPolicy: {{ .Values.image.pullPolicy }}
        ports:
          - name: http
            containerPort: {{ .Values.components.llmserver.port }}
            protocol: TCP
        resources:
          limits:
            cpu: "{{ .Values.components.llmserver.resources.limits.cpu }}"
            memory: "{{ .Values.components.llmserver.resources.limits.memory }}"
            nvidia.com/gpu: 1
        env:
        - name: PORT
          value: "{{ .Values.components.llmserver.port }}"
        livenessProbe:
          tcpSocket:
            port: {{ .Values.components.llmserver.port }}
          initialDelaySeconds: 15
          periodSeconds: 10
      {{- with .Values.nodeSelector }}
      nodeSelector:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.affinity }}
      affinity:
        {{- toYaml . | nindent 8 }}
      {{- end }}
      {{- with .Values.tolerations }}
      tolerations:
        {{- toYaml . | nindent 8 }}
      {{- end }}